{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4e63b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 235788 entries, 0 to 235787\n",
      "Data columns (total 31 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   competition_id  235788 non-null  int64  \n",
      " 1   Amount          235788 non-null  float64\n",
      " 2   V1              235755 non-null  float64\n",
      " 3   V2              235769 non-null  float64\n",
      " 4   V3              235761 non-null  float64\n",
      " 5   V4              235773 non-null  float64\n",
      " 6   V5              235745 non-null  float64\n",
      " 7   V6              235755 non-null  float64\n",
      " 8   V7              235775 non-null  float64\n",
      " 9   V8              235747 non-null  float64\n",
      " 10  V9              235770 non-null  float64\n",
      " 11  V10             235782 non-null  float64\n",
      " 12  V11             235762 non-null  float64\n",
      " 13  V12             235779 non-null  float64\n",
      " 14  V13             235769 non-null  float64\n",
      " 15  V14             235785 non-null  float64\n",
      " 16  V15             235773 non-null  float64\n",
      " 17  V16             235770 non-null  float64\n",
      " 18  V17             235786 non-null  float64\n",
      " 19  V18             235759 non-null  float64\n",
      " 20  V19             235753 non-null  float64\n",
      " 21  V20             235754 non-null  float64\n",
      " 22  V21             235683 non-null  float64\n",
      " 23  V22             235761 non-null  float64\n",
      " 24  V23             235706 non-null  float64\n",
      " 25  V24             235771 non-null  float64\n",
      " 26  V25             235774 non-null  float64\n",
      " 27  V26             235780 non-null  float64\n",
      " 28  V27             235766 non-null  float64\n",
      " 29  V28             235738 non-null  float64\n",
      " 30  Class           235788 non-null  int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 55.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   competition_id        Amount        V1        V2        V3        V4  \\\n",
       " 0          200001   5384.439941  1.073515 -0.357867  0.403438 -0.489846   \n",
       " 1          200002  17982.099610  0.115433 -0.126228  1.760780  0.465503   \n",
       " 2          200003   6901.490234 -0.134323 -0.409743  1.272522 -0.338456   \n",
       " 3          200004  14278.969730 -0.538880 -1.353725  0.316332 -0.270522   \n",
       " 4          200005    210.350006  0.975284 -0.338808  0.802451 -0.201451   \n",
       " \n",
       "          V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       " 0  0.350531  0.427065  0.413984 -0.145682  ... -0.211017 -0.232020 -0.865567   \n",
       " 1  0.338733  0.655035  0.492372 -0.093471  ... -0.419567  0.015181  0.808545   \n",
       " 2  0.973651  0.591710  0.462300 -0.128050  ...  0.405960 -0.148264 -0.494632   \n",
       " 3 -0.038734  1.534834  2.479669 -0.156215  ...  1.870997  0.136272 -0.175280   \n",
       " 4  0.110070  0.066379  0.442581 -0.168338  ... -0.288194 -0.097900  0.000855   \n",
       " \n",
       "         V23       V24       V25       V26       V27       V28  Class  \n",
       " 0 -0.048283 -1.457661  0.470830  0.349344 -0.271379 -0.080280      0  \n",
       " 1 -0.051552  0.026281 -1.654427 -0.052750  0.052670  0.484670      0  \n",
       " 2 -0.129838 -2.025227  0.220023  1.400928 -0.209747  0.094838      0  \n",
       " 3  2.200410 -2.241789  0.968681  1.769608 -0.639085  0.246740      0  \n",
       " 4 -0.032516  1.118852  0.741830 -1.154841 -0.213483 -0.057342      0  \n",
       " \n",
       " [5 rows x 31 columns],\n",
       " None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the training data\n",
    "training_data_path = 'sprint3_transactions.csv'\n",
    "train_df = pd.read_csv(training_data_path)\n",
    "\n",
    "#Preview the datafframe\n",
    "train_df.head(), train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fe941ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Adjusted):\n",
      "[[46574     9]\n",
      " [   28   547]]\n",
      "\n",
      "Classification Report (Adjusted):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     46583\n",
      "           1       0.98      0.95      0.97       575\n",
      "\n",
      "    accuracy                           1.00     47158\n",
      "   macro avg       0.99      0.98      0.98     47158\n",
      "weighted avg       1.00      1.00      1.00     47158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#Put in missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "train_df_imputed = pd.DataFrame(imputer.fit_transform(train_df.drop(columns=['competition_id', 'Class'])),\n",
    "                                columns=train_df.drop(columns=['competition_id', 'Class']).columns)\n",
    "\n",
    "#Normalize the amount column\n",
    "scaler = StandardScaler()\n",
    "train_df_imputed['NormalizedAmount'] = scaler.fit_transform(train_df_imputed[['Amount']])\n",
    "train_df_imputed.drop(columns=['Amount'], inplace=True)\n",
    "\n",
    "#Add the class column back\n",
    "train_df_imputed['Class'] = train_df['Class']\n",
    "\n",
    "#Split the data into features and target\n",
    "X = train_df_imputed.drop(columns=['Class'])\n",
    "y = train_df_imputed['Class']\n",
    "\n",
    "#Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Apply SMOTE cause of class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Train the Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "#Predict class probabilities rather than classes directly\n",
    "y_prob = rf_classifier.predict_proba(X_val)[:, 1] \n",
    "\n",
    "#Choose a new threshold\n",
    "new_threshold = 0.6  \n",
    "\n",
    "#Apply the new threshold to determine class predictions\n",
    "y_pred_adjusted = (y_prob >= new_threshold).astype(int)\n",
    "\n",
    "#Evaluate the model \n",
    "confusion_mat_adjusted = confusion_matrix(y_val, y_pred_adjusted)\n",
    "classification_rep_adjusted = classification_report(y_val, y_pred_adjusted)\n",
    "\n",
    "print(\"Confusion Matrix (Adjusted):\")\n",
    "print(confusion_mat_adjusted)\n",
    "print(\"\\nClassification Report (Adjusted):\")\n",
    "print(classification_rep_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE and Class Weight balance\n",
    "\n",
    "#Just SMOTE\n",
    "#array([[46572,    11],\n",
    "       #[   20,   555]])\n",
    "\n",
    "#Stratify=y\n",
    "#array([[46576,     7],\n",
    "       #[   56,   519]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "efeb0a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46572,    11],\n",
       "       [   19,   556]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "confusion_mat = confusion_matrix(y_val, y_pred)\n",
    "classification_rep = classification_report(y_val, y_pred)\n",
    "\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "558c959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE and Classw weight balanced\n",
    "\n",
    "#Just SMOTE\n",
    "#Class\n",
    "#0    0.987811\n",
    "#1    0.012189\n",
    "\n",
    "#stratify=y\n",
    "#Class\n",
    "#0    0.987811\n",
    "#1    0.012189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "736eb090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    0.987811\n",
      "1    0.012189\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Show me the proportion of each class in the target\n",
    "class_distribution = y.value_counts(normalize=True)  \n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=class_distribution.index, y=class_distribution.values)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary with precision, recall and f1 score\n",
    "report = classification_report(y_val, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e921e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dictionary to DataFrame\n",
    "report_df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc994f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7b4aebf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (339548270.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[81], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    TOO SMALL A DIFFERENCE TO MATTER\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#threshold adjustment to 0.6\n",
    "\n",
    "\n",
    "#threshold adjustment to 0.4 and random trees 200\n",
    "#precision\trecall\tf1-score\tsupport\n",
    "#0\t0.999592\t0.999764\t0.999678\t46583.000000\n",
    "#1\t0.980600\t0.966957\t0.973730\t575.000000\n",
    "#accuracy\t0.999364\t0.999364\t0.999364\t0.999364\n",
    "#macro avg\t0.990096\t0.983360\t0.986704\t47158.000000\n",
    "#weighted avg\t0.999361\t0.999364\t0.999362\t47158.000000\n",
    "\n",
    "#SMOTE NORMALISE AMOUNT AND BALANCE CLASS WEIGHT, but 200 trees\n",
    "#TOO SMALL A DIFFERENCE TO MATTER\n",
    "\n",
    "#SMOTE NORMALISE AMOUNT AND BALANCE CLASS WEIGHT, but 100 trees\n",
    "\n",
    "#precision\trecall\tf1-score\tsupport\n",
    "#0\t0.999571\t0.999764\t0.999667\t46583.000000\n",
    "#1\t0.980565\t0.965217\t0.972831\t575.000000\n",
    "#accuracy\t0.999343\t0.999343\t0.999343\t0.999343\n",
    "#macro avg\t0.990068\t0.982491\t0.986249\t47158.000000\n",
    "#weighted avg\t0.999339\t0.999343\t0.999340\t47158.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "520ea9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBC results:\n",
    "\n",
    "#Confusion Matrix:\n",
    "#[[46083   414]\n",
    "# [  963 45706]]\n",
    "\n",
    "#Classification Report:\n",
    "\n",
    "              #precision    recall  f1-score   support\n",
    "\n",
    "           #0       0.98      0.99      0.99     46497\n",
    "           #9       0.99      0.98      0.99     46669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db309e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the validation set: Save features, actual classes, and predictions\n",
    "validation_results = X_val.copy()\n",
    "validation_results['ActualClass'] = y_val\n",
    "validation_results['PredictedClass'] = y_pred\n",
    "\n",
    "# Save the validation results to a CSV file\n",
    "validation_results.to_csv('RFvalidation_results.csv', index=False)\n",
    "\n",
    "training_results = X_train.copy()\n",
    "training_results['ActualClass'] = y_train\n",
    "\n",
    "\n",
    "training_results.to_csv('RFtraining_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65f67376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been added and saved to '2RF_predictions_with_classes.csv'.\n"
     ]
    }
   ],
   "source": [
    "prediction_data_path = 'sprint3_predictions.csv'\n",
    "predict_df = pd.read_csv(prediction_data_path)\n",
    "\n",
    "#Save the 'competition_id' column if it's going to be dropped during processing\n",
    "if 'competition_id' in predict_df.columns:\n",
    "    competition_id = predict_df['competition_id'].copy()\n",
    "\n",
    "#Drop unwanted columns for prediction\n",
    "predict_df.drop(columns=['competition_id', 'Predicted_class'], errors='ignore', inplace=True)\n",
    "\n",
    "if 'Amount' in predict_df.columns:\n",
    "    predict_df['NormalizedAmount'] = scaler.transform(predict_df[['Amount']])\n",
    "    predict_df.drop(columns=['Amount'], inplace=True)\n",
    "\n",
    "#Predict the classes using the trained model\n",
    "y_pred = rf_classifier.predict(predict_df)\n",
    "\n",
    "#Create a new DataFrame for the output to include 'competition_id' and 'predictions'\n",
    "output_df = pd.DataFrame({\n",
    "    'competition_id': competition_id,\n",
    "    'Predicted_class': y_pred\n",
    "})\n",
    "\n",
    "#Save the Dataframe \n",
    "output_csv_path = '2RF_predictions_with_classes.csv'\n",
    "output_df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599970ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
